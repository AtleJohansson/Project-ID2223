from __future__ import annotations

import os
from pathlib import Path

from dotenv import load_dotenv
import pandas as pd
import streamlit as st
import plotly.graph_objects as go

from components.io import read_parquet_s3

# ---------------------------------------------------------------------
# Load local secrets (.env). Safe in Streamlit Cloud (ignored if missing)
# ---------------------------------------------------------------------
load_dotenv(dotenv_path=Path(__file__).resolve().parent / ".env", override=False)

# ---------------------------------------------------------------------
# Display config (units + formatting)
# ---------------------------------------------------------------------
UNITS = {
    "price": "SEK/kWh",
}

DECIMALS = {
    "price": 3,
}

def fmt(x, decimals: int = 2, unit: str | None = None, na: str = "â€”") -> str:
    try:
        if x is None:
            return na
        if isinstance(x, float) and pd.isna(x):
            return na
        v = float(x)
        s = f"{v:,.{decimals}f}"
        return f"{s} {unit}" if unit else s
    except Exception:
        return na

def axis_title(name: str, unit: str | None = None) -> str:
    return f"{name} ({unit})" if unit else name

# ---------------------------------------------------------------------
# Streamlit config
# ---------------------------------------------------------------------
st.set_page_config(page_title="Predictions", page_icon="ðŸ”®", layout="wide")

st.title("ðŸ”® Predictions")
st.markdown(
    """
This page shows the **latest daily electricity price forecast** generated by our **XGBoost model**.
The model uses the most recent feature values (e.g., weather and market signals stored in the feature store)
to produce a forward-looking prediction horizon. The chart compares the recent historical prices with the
forecasted trajectory, and may optionally include uncertainty bands if available in the forecast output.

All values are displayed with their corresponding units (**SEK/kWh**) and timestamps are shown in **UTC**.
"""
)

st.markdown("---")

# ---------------------------------------------------------------------
# S3 config
# ---------------------------------------------------------------------
bucket = os.environ.get("S3_BUCKET")
if not bucket:
    st.error("S3_BUCKET not set. Add it to your .env or Streamlit secrets.")
    st.stop()

prefix = os.environ.get("S3_PREFIX", "").strip("/")
pred_key = f"{prefix}/forecast_latest.parquet" if prefix else "forecast_latest.parquet"
history_key = f"{prefix}/history.parquet" if prefix else "history.parquet"

# ---------------------------------------------------------------------
# Load data
# ---------------------------------------------------------------------
@st.cache_data(ttl=300)
def load_pred() -> pd.DataFrame:
    return read_parquet_s3(bucket, pred_key)

@st.cache_data(ttl=300)
def load_hist() -> pd.DataFrame:
    return read_parquet_s3(bucket, history_key)

try:
    pred = load_pred()
    hist = load_hist()
except Exception as e:
    st.error("Failed to load prediction/history parquet files from S3.")
    st.exception(e)
    st.stop()

# ---------------------------------------------------------------------
# Normalize schema
# ---------------------------------------------------------------------
TS_COL = "timestamp"
HIST_PRICE_COL = "price"
PRED_COL = "predicted_price"

required_pred = [TS_COL, PRED_COL]
missing_pred = [c for c in required_pred if c not in pred.columns]
if missing_pred:
    st.error(f"forecast_latest.parquet schema mismatch. Missing: {missing_pred}")
    with st.expander("Developer: forecast_latest columns"):
        st.write(list(pred.columns))
    st.stop()

required_hist = [TS_COL, HIST_PRICE_COL]
missing_hist = [c for c in required_hist if c not in hist.columns]
if missing_hist:
    st.error(f"history.parquet schema mismatch. Missing: {missing_hist}")
    with st.expander("Developer: history columns"):
        st.write(list(hist.columns))
    st.stop()

pred = pred.copy()
hist = hist.copy()

pred[TS_COL] = pd.to_datetime(pred[TS_COL], utc=True, errors="coerce")
pred = pred.dropna(subset=[TS_COL]).sort_values(TS_COL)
pred[PRED_COL] = pd.to_numeric(pred[PRED_COL], errors="coerce")

hist[TS_COL] = pd.to_datetime(hist[TS_COL], utc=True, errors="coerce")
hist = hist.dropna(subset=[TS_COL]).sort_values(TS_COL)
hist[HIST_PRICE_COL] = pd.to_numeric(hist[HIST_PRICE_COL], errors="coerce")

# Optional uncertainty columns
LOW_COL = "yhat_lower"
UP_COL = "yhat_upper"
has_uncertainty = (LOW_COL in pred.columns) and (UP_COL in pred.columns)
if has_uncertainty:
    pred[LOW_COL] = pd.to_numeric(pred[LOW_COL], errors="coerce")
    pred[UP_COL] = pd.to_numeric(pred[UP_COL], errors="coerce")

# ---------------------------------------------------------------------
# Sidebar controls (match other pages)
# ---------------------------------------------------------------------
st.sidebar.subheader("Forecast chart controls")

hist_window = st.sidebar.selectbox(
    "Historical context window",
    ["Last 7D", "Last 30D", "Last 90D", "Last 180D", "Last 365D", "All available"],
    index=2,
)

show_uncertainty = st.sidebar.checkbox("Show uncertainty band", value=True) if has_uncertainty else False

# Determine historical subset
hist_min_ts = hist[TS_COL].min()
hist_max_ts = hist[TS_COL].max()

def start_for_hist_window(sel: str) -> pd.Timestamp:
    end = hist_max_ts
    if sel == "Last 7D":
        return end - pd.Timedelta(days=7)
    if sel == "Last 30D":
        return end - pd.Timedelta(days=30)
    if sel == "Last 90D":
        return end - pd.Timedelta(days=90)
    if sel == "Last 180D":
        return end - pd.Timedelta(days=180)
    if sel == "Last 365D":
        return end - pd.Timedelta(days=365)
    return hist_min_ts

hist_start = start_for_hist_window(hist_window)
hist_plot = hist[hist[TS_COL] >= hist_start].copy()

# ---------------------------------------------------------------------
# KPIs
# ---------------------------------------------------------------------
latest_actual = hist[HIST_PRICE_COL].dropna().iloc[-1] if hist[HIST_PRICE_COL].dropna().shape[0] else None
latest_actual_ts = hist[TS_COL].iloc[-1] if len(hist) else None

latest_pred = pred[PRED_COL].dropna().iloc[-1] if pred[PRED_COL].dropna().shape[0] else None
latest_pred_ts = pred[TS_COL].iloc[-1] if len(pred) else None

first_pred = pred[PRED_COL].dropna().iloc[0] if pred[PRED_COL].dropna().shape[0] else None
horizon_points = int(pred[PRED_COL].dropna().shape[0])

delta_last = None
if (latest_actual is not None) and (first_pred is not None):
    delta_last = first_pred - latest_actual

st.markdown("### ðŸ”Ž Summary")
k1, k2, k3, k4 = st.columns(4)
k1.metric("Forecast horizon (points)", f"{horizon_points:,}")
k2.metric("Latest actual", fmt(latest_actual, DECIMALS["price"], UNITS["price"]))
k3.metric("First forecast value", fmt(first_pred, DECIMALS["price"], UNITS["price"]))
k4.metric("Î” first forecast vs latest actual", fmt(delta_last, DECIMALS["price"], UNITS["price"]))

if latest_actual_ts is not None and latest_pred_ts is not None:
    st.caption(f"Latest actual timestamp: {latest_actual_ts} â€¢ Latest forecast timestamp: {latest_pred_ts}")

st.markdown("---")

# ---------------------------------------------------------------------
# Chart: history + forecast (+ optional uncertainty)
# ---------------------------------------------------------------------
st.subheader("ðŸ“ˆ Electricity price forecast")
st.caption(f"Unit: {UNITS['price']} â€¢ Timestamps shown in UTC")

fig = go.Figure()

fig.add_trace(
    go.Scatter(
        x=hist_plot[TS_COL],
        y=hist_plot[HIST_PRICE_COL],
        mode="lines",
        name=f"Historical ({UNITS['price']})",
    )
)

fig.add_trace(
    go.Scatter(
        x=pred[TS_COL],
        y=pred[PRED_COL],
        mode="lines",
        name=f"Forecast ({UNITS['price']})",
        line=dict(dash="dash"),
    )
)

if has_uncertainty and show_uncertainty:
    # build a filled polygon between upper and lower
    x_poly = pred[TS_COL].tolist() + pred[TS_COL].tolist()[::-1]
    y_poly = pred[UP_COL].tolist() + pred[LOW_COL].tolist()[::-1]

    fig.add_trace(
        go.Scatter(
            x=x_poly,
            y=y_poly,
            fill="toself",
            line=dict(width=0),
            name=f"Uncertainty band ({UNITS['price']})",
            showlegend=True,
        )
    )

fig.update_layout(
    template="plotly_dark",
    margin=dict(l=20, r=20, t=40, b=20),
    xaxis_title="Time (UTC)",
    yaxis_title=axis_title("Price", UNITS["price"]),
    height=520,
)

st.plotly_chart(fig, use_container_width=True)

# ---------------------------------------------------------------------
# Tables (with units in headers)
# ---------------------------------------------------------------------
st.subheader("ðŸ“‹ Forecast table")

table = pred.copy()

# Round numeric columns (display-only)
for c in table.columns:
    if c != TS_COL and pd.api.types.is_numeric_dtype(table[c]):
        table[c] = table[c].round(DECIMALS["price"])

# Rename for display
rename_map = {
    TS_COL: "Timestamp (UTC)",
    PRED_COL: f"Forecast ({UNITS['price']})",
}
if has_uncertainty:
    rename_map[LOW_COL] = f"Lower ({UNITS['price']})"
    rename_map[UP_COL] = f"Upper ({UNITS['price']})"

table = table.rename(columns=rename_map)

st.dataframe(table, use_container_width=True)

st.subheader("ðŸ“‹ Latest historical rows (context window)")
hist_table = hist_plot[[TS_COL, HIST_PRICE_COL]].tail(30).copy()
hist_table = hist_table.rename(
    columns={
        TS_COL: "Timestamp (UTC)",
        HIST_PRICE_COL: f"Actual ({UNITS['price']})",
    }
)
st.dataframe(hist_table, use_container_width=True)
